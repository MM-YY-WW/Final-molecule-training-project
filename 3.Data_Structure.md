# 3.Data Structures

## 3.1 Tutorials of Common Data Structures

Finish the following tutorials:

[Python Lists (Python Lists -- List Exercises)](https://www.w3schools.com/python/python_lists.asp)

[Python Sets (Python Sets -- Set Exercises)](https://www.w3schools.com/python/python_sets.asp)

[Python Dictionaries (Python Dictionaries -- Dictionary Exercise)](https://www.w3schools.com/python/python_dictionaries.asp)

[Python Arrays](https://www.w3schools.com/python/python_arrays.asp)

[Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)


## 3.2 Download and Investigate molecular datasets
For molecular property prediction, this paper utilized the following [datasets (Click to Download)](https://snap.stanford.edu/gnn-pretrain/data/chem_dataset.zip). 

Put the unzipped dataset folder into the following directory 

```
/home/nicole/intro/coding/data_structure/ 
```

The data that needs to be analyzed is under /raw directory

For example:

The path raw data of dataset BACE is:

```
/home/nicole/coding/intro/data_structure/dataset/bace/raw/bace.csv
```

:book: Recommend Reading: [MoleculeNet: a benchmark for molecular machine
learning](https://pubs.rsc.org/en/content/articlepdf/2018/sc/c7sc02664a)

:pen: Download and Investigate these datasets, record the data meaning
```
- BBBP:
- Tox21:
- ToxCast:
- SIDER:
- ClinTox:
- MUV: 
- HIV:
- BACE:
```

Use the Data Structures learned just now to generate the following:

### 3.2.1. Sample size 

Load the raw data files (.csv files) into the data frame

Count how many samples there are in each file

### 3.2.2. Task number

If a SMILES sample have multiple labels, then this dataset contains multiple tasks

For example:

```
CC1=NN=C(N1C2CC3CCC(C2)N3CC[C@@H](C4=CC=CC=C4)NC(=O)C5CCC(CC5)(F)F)C(C)C,1,1,0,1,1,1,1

"CC1=NN=C(N1C2CC3CCC(C2)N3CC[C@@H](C4=CC=CC=C4)NC(=O)C5CCC(CC5)(F)F)C(C)C" is the SMILES representation of a molecule

"1,1,0,1,1,1,1" is the label of each task

There are seven tasks in total
```

Use the data structure learned before to print out the task number for each dataset, along with the name of the datasets

### 3.2.3. Unique Label for Each Task

For the labels of each task, may contain several different labels.

For binary classification data, the labels are usually 0, 1

For multi-class classification, the labels could be 0, 1, 2, 3

First, identify the unique labels for each task of the datasets, and save it in a dictionary with keys equal to the name of the datasets, and values equal to a nested list of all unique labels for tasks 

For example:

The data looks like this:

dataset: BACE

SMILES1, 0, 1, 1

SMILES2, 1, 1, 0

SMILES3, 0, 1, 3

SMILES4, 0, 0, 2

Tip: Save the unique labels in ascending order

```
dataset_dictionary = {}
if 'BACE' not in dataset_dictionary.keys():
    dataset_dictionary['BACE'] =  [[0,1],[0,1],[0,1,2,3]]
print(dataset_dictionary)
# result should be {'BACE':[[0,1],[0,1],[0,1,2,3]]}
```

Save the resulting dictionary as .json file named "dataset_dictionary.json"

### 3.2.4. Label ratio

Calculate the percentage of each label for each task for all the datasets. 

Save the results in another dictionary in the following format

dataset: BACE

SMILES1, 0, 1, 1

SMILES2, 1, 1, 0

SMILES3, 0, 1, 3

SMILES4, 0, 0, 2

```
dataset_dictionary = {'BACE':[[0,1],[0,1],[0,1,2,3]]}

label_ratio = {'BACE': [[0.75, 0.25],[0.25, 0.75],[0.25, 0.25, 0.25, 0.25]]}

# Label 0 in task 1 of BACE has ratio 0.75
# Label 1 in task 1 of BACE has ratio 0.25

```

Save the resulting dictionary as .json file named "label_ratio.json"

Congrats! You finish all the tasks for today. Remember to upload the codes and resulting files to GitHub (don't upload the dataset folder, sense it is pretty large) 
