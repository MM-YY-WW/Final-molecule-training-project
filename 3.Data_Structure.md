# 3.Data Structures

## 3.1 Tutorials of Common Data Structures

Finish the following tutorials:

[Python Lists (Python Lists -- List Exercises)](https://www.w3schools.com/python/python_lists.asp)

[Python Sets (Python Sets -- Set Exercises)](https://www.w3schools.com/python/python_sets.asp)

[Python Dictionaries (Python Dictionaries -- Dictionary Exercise)](https://www.w3schools.com/python/python_dictionaries.asp)

[Python Arrays](https://www.w3schools.com/python/python_arrays.asp)

[Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)


## 3.2 Download and Investigate molecular datasets
For molecular property prediction, this paper utilize the following [datasets (Click to Download)](https://snap.stanford.edu/gnn-pretrain/data/chem_dataset.zip). 

Put the unziped dataset folder to the following directory 

```
/home/nicole/coding/data_structure/ 
```

The data that needs to be analized is under /raw directory

For example:

The path raw data of dataset BACE is:

```
/home/nicole/coding/data_structure/dataset/bace/raw/bace.csv
```

:book: Recommend Reading: [MoleculeNet: a benchmark for molecular machine
learning](https://pubs.rsc.org/en/content/articlepdf/2018/sc/c7sc02664a)

:pen:Download and Investigate these dataset, record the data meaning
```
- BBBP:
- Tox21:
- ToxCast:
- SIDER:
- ClinTox:
- MUV: 
- HIV:
- BACE:
```

Use the Data Structures learned just now to generate the:

1. Sample size 

Load the raw data files (.csv files) in to dataframe

Count how many of sample are there in each file

2. Task number

If a SMILES sample have multiple lables, then this dataset contains multiple tasks

For example:

```
CC1=NN=C(N1C2CC3CCC(C2)N3CC[C@@H](C4=CC=CC=C4)NC(=O)C5CCC(CC5)(F)F)C(C)C,1,1,0,1,1,1,1

"CC1=NN=C(N1C2CC3CCC(C2)N3CC[C@@H](C4=CC=CC=C4)NC(=O)C5CCC(CC5)(F)F)C(C)C" is the SMILES representation of a molecule

"1,1,0,1,1,1,1" is the labels of each task

There are seven tasks in total
```

Use the data structure learned before to print out the task number for each dataset, along with the name of the datasets

3. Unique Label for Each Task

For the labels of each task, it may contains several different labels.

For binary classification data, the labels are usually 0, 1

For multi-class classification, the labels could be 0, 1, 2, 3

First, identity the unique labels for each task of the datasets, save it in a dictionary with key equals to the name of dataset and value be a nested list of all unique labels for each task. 

For example:

The data looks like:

dataset: BACE

SMILES1, 0, 1, 1

SMILES2, 1, 1, 0

SMILES3, 0, 1, 3

SMILES4, 0, 0, 2

Tip: Save the unique labels in ascending order

```
dataset_dictionary = {}
if 'BACE' not in dataset_dictionary.keys():
    dataset_dictionary['BACE'] =  [[0,1],[0,1],[0,1,2,3]]
print(dataset_dictionary)
# result should be {'BACE':[[0,1],[0,1],[0,1,2,3]]}
```

Save the resulting dictionary as .json file named "dataset_dictionary.json"

4. Label ratio

Calculate the percentage of each label for each task for all the datasets. 

Save the results in another dictionary as the following format

dataset: BACE

SMILES1, 0, 1, 1

SMILES2, 1, 1, 0

SMILES3, 0, 1, 3

SMILES4, 0, 0, 2

```
dataset_dictionary = {'BACE':[[0,1],[0,1],[0,1,2,3]]}

label_ratio = {'BACE': [[0.75, 0.25],[0.25, 0.75],[0.25, 0.25, 0.25, 0.25]]}

# Label 0 in task 1 of BACE has ratio 0.75
# Label 1 in task 1 of BACE has ratio 0.25

```

Save the resulting dictionary as .json file named "label_ratio.json"

